---
layout:     post
title:      UMAP:均匀流形逼近和投影的降维方法
subtitle:   Uniform Manifold Approximation and Projection
date:       2020-01-13
author:     朱晓旭
header-img: img/umap_bg2.png
catalog: true
tags:
    - umap
    - manifold
    - manifold learning
    - 降维
    - 流形学习	
---

## 前言
**降维**本质上是在能够保留数据内部结构关系的前提下得到高维数据空间的一个低维表达。

**UMAP**(Uniform Manifold Approximation and Projection,均匀流形近似和投影)，通过构建加权k neighbor图，然后对图进行做低维分布。  
umap假设数据在黎曼流行空间上呈现均匀分布，并且局部数据与欧式空间是同胚的。它假设的目的是为了在计算kNN图的时候能够使用欧式空间的距离度量且能表达局部数据之间的关系。

**理解**：为了方便理解可以把数据点比作分布在地球上一个一个的城市，它们分布在三维欧氏空间，uamp投影的目的是把一系列城市的位置投影到二维，并且能区分在哪个国家。地球表面相当于一个在三维欧氏空间的一个二维黎曼流形，这是第一点假设，我们地球上的城市是分布均匀的，并且当我们测量局部区域的两个城市之间的距离的时候我们假设两个城市是在二维欧氏空间的，我们可以把测地线近似的等于欧式空间的距离(圆上很近的两点之间的弧线长度和线段长度近似)，这是第二个假设。我们通过做局部kNN图，然后联合分析做出全局的graph，把数据特征投影到低维流形，就能达成目的。第二个假设的目的是，黎曼流形空间中的距离和欧氏空间距离不同(比方说中国到阿根廷的距离，在流形空间中是地球的球半周长，在欧氏空间中是地球的直径)，但是局部分析时近似。

## python包使用以及参数解析

`import umap`  
`prejected = umap.UMAP().fit_transform(data)`

**参数解析**

n_neighbors=15，   
>kNN的样本数量。它越大看到的信息越全局，越小则越局部。文档推荐2到100。  

n_components=2,  
>降维后的维度，默认是2.文档推荐2到100.  

metric="euclidean",  
>距离计算方式，源码中有二十几种。默认欧式。  

n_epochs=None,  
>迭代次数，设置越大越精确。默认是None，是指会基于数据集大小设置。  

learning_rate=1.0,  
>初始学习率。  

init="spectral",    
>初始的低维的embedding：可以是spectral：用PCA的降维结果,'random'：随机的 或者是一个np数组。  

min_dist=0.1,  
>嵌入点之间的最小距离。越小则同类的距离越近。(完全相同的embedding不在一个点上的原因就在这儿)   

spread=1.0,  
>嵌入点的范围，它和min_dist共同决定了集群的分布情况。  

set_op_mix_ratio=1.0,   
>模糊集合论内容： 在模糊交集运算和并集运算之间插值，用模糊局部简单集获取全局简单集。两种模糊集运算都采用t范数。数值介于0和1之间。1是指纯并集，0是纯交集。  

local_connectivity=1.0,  
>“局部”的临界点。大于该距离，不算局部。该值越大，流形中的假设满足欧式空间的距离的局部区域越大。  

repulsion_strength=1.0,  
>在低维嵌入中将该权值应用于负样本。 值大于1会导致负样本的权重更大。计算梯度的时候用。  

negative_sample_rate=5,  
>在优化过程中要为每个正样本选择的负样本数。 增大该值将导致施加更大的排斥力，更大的优化成本，但精度更高。  

transform_queue_size=4.0,   
a=None,b=None,  
>他俩控制传入的参数  

random_state=None,  
>随机的一个单位向量，用于rp-tree算法构建kNN图  

metric_kwds=None,  
>其他参数  

angular_rp_forest=False,  
>是否使用rp树，它能提高速度  

target_n_neighbors=-1,
>用于构造全局的target simplcial set的最近neighbor数。 如果设置为-1，则使用n_neighbors值  

target_metric="categorical",  
target_metric_kwds=None,  
target_weight=0.5,  

transform_seed=42,
>随机种子为保证每次运行的一致性

verbose=False,

## 过程

1. pairwise_distances()计算两两距离
2. fuzzy_simplicial_set()从局部得到整体的概率图
	* nearest_neighbors()得到局部的所有点的下标和他们的距离
	* smooth_knn_dist()得到局部的k个最近的点，和距离每个点最近的点
	* compute_membership_strengths()得到他们的坐标和分类概率
	* scipy.sparse.coo_matrix得到整体概率图

### 相关知识补充

**流形**：是局部具有欧式空间性质的空间，是欧式空间中的曲线、曲面等概念的推广。欧几里得空间就是最简单的流形的实例。地球表面这样的球面则是一个稍微复杂的例子。(维基百科)
个人理解：和高维空间同胚的低维空间，其根本大概是是更低的自由度表达。比方说表达一个固定半径的圆的位置，在二维欧氏空间两个自由度来表达，在一维的流形空间只自由度为一，能实现的原因是数据有冗余。  
**流形学习** ：假设数据是均匀采样于一个高维欧氏空间中的低维流形，流形学习就是从高维采样数据中恢复低维流形结构，即找到高维空间中的低维流形，并求出相应的嵌入映射，以实现维数约简或者数据可视化。(维基百科)
个人理解：机器学习的本质就是参数估计，流形学习也是同样，它所构建的模型是把数据从高维欧氏空间唯一映射到低维黎曼空间的F。流形学习除了去除冗余信息数据降维外，还能探究数据特征分布的本质。同时，在SV中我们使用余弦相似度衡量高维数据之间的距离是不精确的，因为该256维数据中带有的冗余特征。  
**同胚**：是两个拓扑空间之间的双连续函数，满足：双射(单射+满射)，双连续(f(x)和f(y))。  
**随机投影树**(Random Projection Tree)：参考[Random projection trees and low dimensional manifolds](https://cseweb.ucsd.edu/~dasgupta/papers/rptree-stoc.pdf)。它用来计算kNN图，kNN图用于寻找流形。每次umap生成都不同就是因为此随机性。

### 参考

- [官方文档](https://umap-learn.readthedocs.io/en/latest/index.html)
- [源码](https://github.com/lmcinnes/umap)
- [论文](https://arxiv.org/pdf/1802.03426.pdf)
- [报告](https://www.youtube.com/watch?v=nq6iPZVUxZU&frags=pl%2Cwn)


