---
layout:     post
title:      LPCNet理解
subtitle:   LPCNet：IMPROVING NEURAL SPEECH SYNTHESIS THROUGH LINEAR PREDICTION
date:       2020-01-13
author:     朱晓旭
header-img: img/bg.jpg
catalog: true
tags:
    - LPC
    - LPCNet
    - Vocoder
    - 声码器
    - 神经网络声码器
    - 轻量级
    - 实时声码器	
---


## LPCNet模型理解

人发声音是通过人肺部挤压出来的气流通过声带产生震动波，通过空气传播到我们的耳朵。物理学用声源激励(模拟从肺部发出气流)和声道响应系统可以构建传统声码器。  
- 声源过滤器模型(Source–filter model)就是这种模型，它的声道模型就是LPC这种，激励是开关（清音 浊音还是其他无声之类的）。响应系统是过去时间段里面的声音的振幅变种的线性组合。  
- 神经网络模型是把声源激励模型和声道响应用一组神经网络建模(计算量很大)。  
- LPCNet是两者结合，用LPC做响应系统，用神经网络做声源激励模型（把残差信号当作激励源）（文中还提出了另一个好处就是补偿了u-law的量化噪声）。它计算量小，3GFLOPS，可能在智能机上架设，物理+神经网络保证了良好的预测。  

**理解**：神经网络构建激励信号系统很好理解，此处重点理解物理模型的构建。也就是没有激励信号的每一时刻，他们的输出呈现怎样的关系又是如何建模。想象此刻在空旷的舞台上一位大佬正兴奋的演讲，讲到兴奋处突然麦停止工作了，但下一时刻我们耳朵仍然有余音传入。分析这一时刻，相当于给过激励后突然停止，此刻相当于整个系统的零输入响应，系统内有能量存余，求解此刻后的后波形问题就是解零输入响应微分方程。微分方程的解是基于时间戳的线性组合，和LPC物理建模的表达式相同:  
<center>$$y_{zi}(t)=\sum_{i=1}^{n}C_{i}e^{\lambda_{i}t}$$</center>

## 模型结构
下图展示了LPCNet的模型结构。它由三个部分组成：帧级别网络，采样点级别网络和LPC线性预测模块。帧级别网络用于特征提取，采样点级别网络用于预测激励信号(残差),LPC预测模块根据前N个时刻的值的线性组合预测下一时刻的(注意这里的系数不是训练参数)。
![lpcnet](/img/lpcnet.png)

#### 线性预测
<center>$$p_t=\sum_{k=1}^{M}{\alpha}_ks_{t-k}$$</center>
是一阶线性响应系统，认为每一时刻的幅值变种是上N个时刻（文中取16）的线性组合加上残差信号。残差信号作为激励源将决定下一个时刻声音幅值走向。s是前M（论文中取16）个采样点的振幅变种（变换过），$p_t$是预测系数。预测系数在进入神经网络前已经基于future计算好(Levinson-Durbin算法，看了一下是用迭代法降低复杂度到N平方)，预测时s就是合成的振幅变种。

#### Frame rate network
该网络是帧级别，20维特征穿过两个串联的两个卷积网络和全连接层用来提取该帧的语言特征。该特征作为条件向量或者说是辅助特征输入到sampe rate network。理解为我们SV中的embedding，它包含了整个帧的语音学特征。需要注意的是，在采样级别网络中的当前帧，该向量是保持不变的。

#### Sample rate network
该网路是采样点级别，输入时concat特征向量，上一时刻的激励信号，上一时刻的幅值变种预测，以及响应预测。然后经过两层GRU(第一层细胞多，训练时逐步把weight小的细胞置零减小运算量，第二层细胞少，具体量是？和？)，然后进入Dual FC网络(计算机视觉的卷积手法，文中使用应该是网络并行减少运算量)，经过softmax预测激励的概率分布(文中讲顺带解决了量化噪声原因是？？？)。LOSS是采样点真实值和预测值的差。


## 论文分析
#### pre-emphsis
pre-emphsis滤波来提升高频能量，是个一阶高通滤波器。采用pre-enphsis的理由是$\mu$-law量化噪声在高频段更能明显听出来，因为高频量化后有所衰减，所以高频量化噪声大。因此通过pre-emphsis加大高频的能量，使量化后更均衡。最后还可以通过de-emphsiis去除。系数0.85决定了阈值，是试验出来的把。
<center>$$D(z) = \frac{1}{1-{\alpha}z^{-1}}$$</center>
下图横坐标是频率，纵坐标是映射比例。  
![lpcnet](/img/preemphsis.png)

#### $\mu$-law transfer
<center>$$F(x) = \frac{sgn(x)ln(1+{\mu}|x|)}{ln(1+{\mu})}$$</center>

$\mu$-law同样只是一种刻度映射，类似mel刻度映射。下图是映射关系图。
![lpcnet](/img/u_law.png)

#### 加噪处理
文中在量化加入噪声后求激励值，并且把上一时刻的预测值作为输入进入下一时刻，减少训练和预测的误差。具体噪声类型？。
![lpcnet](/img/lpcnet_noise.png)





### 参考

- [LPCNet: Improving Neural Speech Synthesis Through Linear Prediction](https://arxiv.org/pdf/1810.11846.pdf)
- [LPCNet issues](https://github.com/mozilla/LPCNet/issues/4#issuecomment-440994845)





