<center>
    <h1>朱晓旭</h1>
    <div>
        <span>
            <img width="18px">
            [个人主页](https://zhuxiaoxu.com/)
        </span>
       ·
        <span>
            <img width="18px">
            zhuxx23@mails.tsinghua.edu.cn
        </span>
        ·
        <span>
            <img width="18px">
            高级语音算法研发
        </span>
        ·
        <span>
            <img width="18px">
            微信:18701538360
        </span>
    </div>
</center>

---

## 教育背景

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>清华大学</strong><br>
工程管理(信息方向)
</div>
<div style="text-align: right; white-space: nowrap;">
2023 - 2025 (Exp.)<br>
M.Eng.
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>圣彼得堡彼得大帝理工大学</strong><br>
信息学与计算技术
</div>
<div style="text-align: right; white-space: nowrap;">
2017 - 2019<br>
M.S.
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>哈尔滨工业大学</strong><br>
材料成型及其控制工程
</div>
<div style="text-align: right; white-space: nowrap;">
2012 - 2016<br>
B.Eng.
</div>
</div>

## 工作经历

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>商汤科技(SenseTime)</strong> | 高级语音算法开发
</div>
<div style="text-align: right; white-space: nowrap;">
2021.09 - 至今
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>上海人工智能国家实验室(Shanghai AI Lab)</strong> | 算法顾问
</div>
<div style="text-align: right; white-space: nowrap;">
2022.06 - 2023.06
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>猎豹(猎户星空)</strong> | 语音算法工程师
</div>
<div style="text-align: right; white-space: nowrap;">
2019.10 - 2021.09
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>西门子(Siemens)</strong> | 算法实习生
</div>
<div style="text-align: right; white-space: nowrap;">
2018.05 - 2019.09
</div>
</div>


## 学术论文

**Robust Residual Finite Scalar Quantization for Neural Compression**  
**Xiaoxu Zhu**, Jiakui Li, Ken Zheng, Guiping Zhong, Huimeng Wang, Shiyin Kang, Dahua Lin  
*Manuscript in preparation for ICASSP 2026* | [PDF](https://cmsworkshops.com/ICASSP2026/Papers/Uploads/Proposals/PaperNum/17883/20250918064421_486976_17883.pdf)  
*Proposes RFSQ framework that addresses residual magnitude decay problem in finite scalar quantization .*

**Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability**  
**Xiaoxu Zhu**,Junhua Li, Aaron J. Li, Yiming Ren, Baoxiang Li  
*Manuscript in preparation for ICASSP 2026* | [PDF](https://cmsworkshops.com/ICASSP2026/Papers/Uploads/Proposals/PaperNum/16492/20250918064850_184179_16492.pdf)  
*Introduces interpretability-based approach for speaker disentanglement in speech models using SHAP techniques, reducing timbre residual from 18.05% to near 0% while preserving content integrity.*

**InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue**  
Wenwen Tong, Hewei Guo, Dongchuan Ran, ...,  **Xiaoxu Zhu**, ..., Shiyin Kang, Lewei Lu | [共一]  
*Technical Report* | [pdf](https://arxiv.org/pdf/2510.13747)  
*Proposes an open-source 4B-8B omni-modal model for audio-visual multi-turn dialogue, integrates diverse encoders/decoders, boasting strong memory, speech generation and high parameter efficiency.*

**A polyphone BERT for Polyphone Disambiguation in Mandarin Chinese**  
Song Zhang, Ken Zheng, **Xiaoxu Zhu**, Baoxiang Li  
*Interspeech 2022* | [PDF](https://www.isca-archive.org/interspeech_2022/zhang22b_interspeech.pdf)  
*Develops a Chinese polyphone BERT model by extending pre-trained BERT with 741 new monophonic characters, achieving 2% improvement in polyphone disambiguation accuracy for TTS systems.*

**Multimodal Sentiment Analysis via Efficient Multimodal Transformer and Modality-Aware Adaptive Training Strategy**  
C. Ding, D. Zong, B. Li, S. Zhang, **X. Zhu**, G. Zhong, D. Zhou
*IEEE/ACM MuSe-Mimic 2023* | [PDF](https://dl.acm.org/doi/10.1145/3606039.3613113)  
*Presents an efficient multimodal transformer with modality-aware training strategy for sentiment analysis, achieving 0.729 Pearson correlation coefficient and ranking 2nd in the MuSe-Mimic challenge.*

## 项目经历

<div style="font-size: 14px;">

### 大模型语音生成算法 | 2023.4 - 现在 | 商汤科技
负责SenseCosy大语音模型的训练和优化,对S2流式改进实现semantic到audio的低损失流式推理架构；SoVITS方案优化训练调优、流式适配、VQ模块优化等关键工作；多语言方面，实现粤语快速适配，上线商量大模型，测评优于豆包、微软；多子带声码器训练和流式工作，实现声音效果优化，效果满足上线需求已上线商量多模态解决方案；

### 大模型数据处理 | 2023.4 - 2023.9 | 商汤科技  
参与设计并搭建语音处理Pipeline，处理近**250万小时**数据,产出约**50万小时**高质量语音大模型数据,涵盖中文、英文、粤语三个语种;中英文对话、有声书、有声剧、播客、直播、儿童剧、高采样率音频;

### 传统语音合成系统 | 2021.9 - 2023.4 | 商汤科技   
主导商汤第一代语音合成系统架构设计，基于SME的attention优化Tacotron模型，多子带LPCNet优化推理速度服务数字人、智能车舱、下棋机器人、直播数字人等;多音字优化: 预置多音字embedding方案，提升预测准确率;实时声音转换：搭建实时声音转换平台，实现数字人实时语音转换,上线元宇宙项目和直播数字人;

### 情感语音合成和声码器 | 2021.1 - 2021.9 | 猎户星空
基于GST增加上下文输入到TTS的算法实现在少量开源数据集上实现丰富的TTS情感表达显著提升语音合成的情感表现力和自然度，上线猎豹机器人家族;LPCNet声码器优化: Bunched和Multiband LPCNet算法开发与优化;Bunched单线程推理速度**4.2倍**实时，Multiband推理速度**5.3倍**实时;GRU和condition vector预计算提速约10%，贡献到LPCNet官方仓库;成功上线送餐机器人产品;

### 深度学习语音合成 | 2019.02 - 2019.09 | 西门子        
基于Tacotron2开发端到端seq2seq-CWRNN-attention模型(毕业论文),创新性在TTS中使用CWRNN架构,实现字符级别到梅尔波谱级别的高质量映射,MOS测试显示在自然度方面表现优秀; ARTMAP两端逻辑判断和模糊分类的混合架构,手写体字母识别准确率达到**91%**;

</div>

## 发明专利

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
多音字读音预测网络的训练方法、语音生成方法及装置
</div>
<div style="text-align: right; white-space: nowrap;">
CN115273809B
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
残差网络的训练和语音合成方法、装置、设备及介质
</div>
<div style="text-align: right; white-space: nowrap;">
CN112562655A
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
模型训练和语音合成方法、装置、设备及介质
</div>
<div style="text-align: right; white-space: nowrap;">
CN116206591A
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
一种模型训练和语音合成方法、装置、设备及介质
</div>
<div style="text-align: right; white-space: nowrap;">
CN115294955B
</div>
</div>

## 科研项目

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 8px; font-size: 14px;">
<div>
<strong>基于生成式大模型的公路路基突发性灾害预警技术与方法</strong><br>
<strong>专题负责人</strong> | 国家自然科学基金委员会高技术研究发展中心 | SQ2024YFB2600035
</div>
<div style="text-align: right; white-space: nowrap;">
国家重点课题
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 8px; font-size: 14px;">
<div>
<strong>基于语义知识图谱的建筑工程标准国际化共性关键技术</strong><br>
<strong>项目骨干</strong> | 中国21世纪议程管理中心 | SQ2024YFC3800085
</div>
<div style="text-align: right; white-space: nowrap;">
国家重点课题
</div>
</div>


## 竞赛获奖

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>Intel Hackathon</strong> - Excellent Work Award
</div>
<div style="text-align: right; white-space: nowrap;">
2024
</div>
</div>

<div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; font-size: 14px;">
<div>
<strong>ACM MuSe-Mimic Subchallenge</strong> - Second Place
</div>
<div style="text-align: right; white-space: nowrap;">
2023
</div>
</div>

## 开源贡献

<div style="font-size: 14px;">

**LPCNet - Pre-compute GRU B Conditioning**   
*性能优化贡献* | [GitHub Commit](https://github.com/xiph/LPCNet/commit/c1e85f88d908533c5600dbdd800ac589e15747f4)|实现GRU B条件向量预计算，LPCNet推理速度提升约**10%**;通过缓存频繁使用的条件向量，显著减少计算开销;改进实时语音合成性能，为工业级应用提供支持

</div>


