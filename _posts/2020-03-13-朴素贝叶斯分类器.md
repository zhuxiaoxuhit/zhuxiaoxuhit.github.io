---
layout:     post
title:      朴素贝叶斯分类器
subtitle:   Naive Bayes classifier
date:       2020-03-13
author:     朱晓旭
header-img: img/bg.jpg
catalog: true
tags:
    - 朴素贝叶斯分类器
    - Naive Bayes classifier
    - 概率图模型
    - 条件独立性假设
---
# 朴素贝叶斯假设
朴素贝叶斯是最简单的有向概率图模型，它的核心思想是条件独立性假设。
条件独立性假设(朴素贝叶斯假设)：在给定类别的情况下，属性(特征)之间是相互独立的。
$${x_{i}}\bot{x_{j}}| y (x!=j)$$
x是p维特征，y是类别，概率模型如下所示：
$$y\in\{0,1\},x\in{\mathbb{R}}_{p}$$
!()[/img/nbc_1.png]
# 假设动机 
朴素贝叶斯假设的动机是简化$P(X|y)$。
随着特征的维度增加，链式法则下联合概率的计算复杂度高，计算困难。
$$P(x|y)=P(x_{1})\prod_{i = 2}^{p}P({x_{i}}|y,x_{1:i-1}))$$
基于朴素贝叶斯假设：
$$P(X|y)=\prod_{j = 1}^{p}P({x_{j}}|y)$$
同时我们也能够理解，马氏链和引申的条件独立性假设都是基于同样的目的，简化特征的联合概率。
# 朴素贝叶斯分类器
数据是data:
$$\{(x_{i},y_{i})\}_{i=1}^{N}$$
$$y_{i}\in\{0,1\},x_{i}\in{\mathbb{R}}_{p}$$
预测目标是：给定x情况下，预测y属于哪类。
$$y^hat = \mathop{\arg\max}_{y}P(y|x) $$
$$=\mathop{\arg\max}_{y}{\frac{P(x,y)}{P(x)}}$$
由于$P(y|x)={\frac{P(x,y)}{P(x)}}={\frac{P(y)P(x|y)}{P(x)}}\propto{P(y)P(x|y)}$
因此：
$$y^hat = \mathop{\arg\max}_{y}P(y)P(x|y)$$
P(x|y)可以用极大似然估计求解。

#例子





### 参考

- [机器学习-周志华(西瓜书)](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf)





