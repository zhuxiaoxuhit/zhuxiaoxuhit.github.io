---
layout: default
description: "Xiaoxu Zhu (朱晓旭) - Speech AI researcher focusing on large speech models and speech generation"
keyword: "Xiaoxu Zhu,朱晓旭,Speech AI,TTS,Speech Generation,Large Language Models,Deep Learning,Machine Learning,SenseTime,Researcher,AI Scientist"
---

<head>
    {% include head.html %}
    <style>
        /* 移除之前的伪元素方法 */
        
        /* 响应式设计：手机端适配 */
        @media (max-width: 768px) {
            /* About Me 部分手机端适配 */
            .about-me-flex {
                flex-direction: column !important;
                align-items: center !important;
                gap: 15px !important;
            }
            
            .about-me-image {
                text-align: center !important;
                margin-bottom: 15px;
            }
            
            .about-me-image img {
                width: 150px !important;
                max-width: 150px !important;
            }
            
            /* Publications 部分手机端适配 */
            .publication-flex {
                flex-direction: column !important;
                align-items: center !important;
                gap: 15px !important;
            }
            
            .publication-image {
                text-align: center !important;
                margin-bottom: 15px;
            }
            
            .publication-image img {
                width: 120px !important;
                max-width: 120px !important;
            }
            
            .publication-content {
                text-align: left !important;
            }
        }
    </style>
    <script>
        // 修复导航锚点定位
        document.addEventListener('DOMContentLoaded', function() {
            // 获取所有包含锚点的导航链接
            const navLinks = document.querySelectorAll('a[href*="#"]');
            
            navLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    const href = this.getAttribute('href');
                    
                    // 检查是否是锚点链接
                    if (href.includes('#')) {
                        const hashIndex = href.indexOf('#');
                        const targetId = href.substring(hashIndex + 1);
                        
                        // 只处理当前页面的锚点
                        if (targetId && document.getElementById(targetId)) {
                            e.preventDefault();
                            
                            const targetElement = document.getElementById(targetId);
                            
                            // 动态计算导航栏高度
                            const navbar = document.querySelector('.navbar-fixed-top');
                            let navbarHeight = 40; // 减少偏移量，让位置向下
                            
                            if (navbar) {
                                navbarHeight = navbar.offsetHeight - 10; // 减少额外间距
                            }
                            
                            const targetPosition = targetElement.offsetTop - navbarHeight;
                            
                            // 平滑滚动到目标位置
                            window.scrollTo({
                                top: Math.max(0, targetPosition), // 确保不会滚动到负位置
                                behavior: 'smooth'
                            });
                        }
                    }
                });
            });
        });
    </script>
</head>

<!-- About Me Section -->
<div class="container" style="margin-top: 50px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <div class="site-heading">
                <h1 style="margin-bottom: 30px;"><i class="fa fa-home"></i> About Me</h1>
            </div>
            
            <div style="margin-bottom: 25px;">
                <div style="padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <div class="about-me-flex" style="display: flex; align-items: flex-start; gap: 20px;">
                        <div class="about-me-image" style="text-align: center; flex-shrink: 0;">
                            <img src="/img/zhuxiaoxu.png" alt="Xiaoxu Zhu" style="width: 200px; max-width: 200px; border-radius: 10px;">
                        </div>
                        <div style="flex: 1;">
                            <p style="font-size: 16px; line-height: 1.6; margin: 0 0 6px 0;">
                                I am Xiaoxu Zhu (朱晓旭), a Speech AI researcher focusing on large speech models and speech generation. I have been working on speech algorithm research and development at <a href="https://www.sensetime.com/" target="_blank" style="color: #0085a1; text-decoration: none;">SenseTime</a> since 2021. I have also worked or interned at <a href="https://www.siemens.com/" target="_blank" style="color: #0085a1; text-decoration: none;">Siemens</a>, <a href="https://www.cmcm.com/" target="_blank" style="color: #0085a1; text-decoration: none;">Cheetah Mobile</a>, and <a href="https://www.shlab.org.cn/" target="_blank" style="color: #0085a1; text-decoration: none;">Shanghai AI Lab</a>.
                            </p>
                            <p style="font-size: 16px; line-height: 1.6; margin: 0;">
                                I am expected to receive my Master's degree in Information Management from <a href="https://www.tsinghua.edu.cn/" target="_blank" style="color: #0085a1; text-decoration: none;">Tsinghua University</a> in 2025 while working. I received my Bachelor's degree from <a href="https://www.hit.edu.cn/" target="_blank" style="color: #0085a1; text-decoration: none;">Harbin Institute of Technology</a> in 2016, and my Master's degree in Informatics and Computing Technology from <a href="https://spbstu.ru/" target="_blank" style="color: #0085a1; text-decoration: none;">Peter the Great St. Petersburg Polytechnic University</a> in 2019.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Education Section -->
<div id="education" class="container" style="margin-top: 0px; padding-top: 10px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <h2 style="color: #333; margin-bottom: 20px;"><i class="fa fa-graduation-cap"></i> Education</h2>
            
            <div style="margin-bottom: 25px;">
                                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 20px; padding: 20px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div>
                                <div style="display: flex; align-items: flex-start; gap: 15px;">
                                    <a href="https://www.tsinghua.edu.cn/" target="_blank">
                                        <img src="/img/logos/tsinghua.jpeg" alt="Tsinghua University Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                    </a>
                                    <div>
                                        <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                            Tsinghua University
                                        </h3>
                                        <p style="margin: 0; color: #333; font-size: 16px;">Master's Degree in Engineering Management (Information Management)</p>
                                    </div>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2023 - 2025</span>
                        </div>
                    </li>
                                        
                    <li style="margin-bottom: 20px; padding: 20px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div>
                                <div style="display: flex; align-items: flex-start; gap: 15px;">
                                    <a href="https://spbstu.ru/" target="_blank">
                                        <img src="/img/logos/spbstu.jpeg" alt="SPbSTU Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                    </a>
                                    <div>
                                        <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                            Peter the Great St. Petersburg Polytechnic University
                                        </h3>
                                        <p style="margin: 0; color: #333; font-size: 16px;">Master's Degree in Informatics and Computing Technology</p>
                                    </div>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2017 - 2019</span>
                        </div>
                    </li>
                                        
                    <li style="margin-bottom: 20px; padding: 20px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div>
                                <div style="display: flex; align-items: flex-start; gap: 15px;">
                                    <a href="https://www.hit.edu.cn/" target="_blank">
                                        <img src="/img/logos/hit.jpeg" alt="HIT Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                    </a>
                                    <div>
                                        <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                            Harbin Institute of Technology
                                        </h3>
                                        <p style="margin: 0; color: #333; font-size: 16px;">Bachelor's Degree in Materials Forming and Control Engineering</p>
                                    </div>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2012 - 2016</span>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>

<!-- Experience Section -->
<div id="experience" class="container" style="margin-top: 0px; padding-top: 10px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <h2 style="color: #333; margin-bottom: 20px;"><i class="fa fa-briefcase"></i> Work Experience</h2>
            
            <div style="margin-bottom: 25px;">
                                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                                <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div style="display: flex; align-items: flex-start; gap: 15px;">
                                <a href="https://www.sensetime.com/" target="_blank">
                                    <img src="/img/logos/sensetime.jpeg" alt="SenseTime Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                </a>
                                <div>
                                    <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                        SenseTime
                                    </h3>
                                    <p style="margin: 0 0 10px 0; color: #333; font-size: 16px; font-weight: 500;">Speech AI Researcher</p>
                                    <p style="margin: 0; color: #666; font-size: 14px; line-height: 1.6;">Large speech models, speech generation algorithms, and TTS systems.</p>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2021.09 - Present</span>
                        </div>
                    </li>
                                        
                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                                <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div style="display: flex; align-items: flex-start; gap: 15px;">
                                <a href="https://www.shlab.org.cn/" target="_blank">
                                    <img src="/img/logos/shlab.jpeg" alt="Shanghai AI Laboratory Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                </a>
                                <div>
                                    <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                        Shanghai AI Lab
                                    </h3>
                                    <p style="margin: 0 0 10px 0; color: #333; font-size: 16px; font-weight: 500;">Algorithm Consultant</p>
                                    <p style="margin: 0; color: #666; font-size: 14px; line-height: 1.6;">Speech processing and machine learning technologies in speech synthesis.</p>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2022.06 - 2023.06</span>
                        </div>
                    </li>
                    
                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                                <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div style="display: flex; align-items: flex-start; gap: 15px;">
                                <a href="https://www.cmcm.com/" target="_blank">
                                    <img src="/img/logos/cheetah.jpeg" alt="OrionStar Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                </a>
                                <div>
                                    <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                        Cheetah Mobile (OrionStar)
                                    </h3>
                                    <p style="margin: 0 0 10px 0; color: #333; font-size: 16px; font-weight: 500;">Speech AI Researcher</p>
                                    <p style="margin: 0; color: #666; font-size: 14px; line-height: 1.6;">Emotional speech synthesis and neural vocoder optimization.</p>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2019.10 - 2021.09</span>
                        </div>
                    </li>
                    
                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                                <div style="display: flex; justify-content: space-between; align-items: flex-start; flex-wrap: wrap;">
                            <div style="display: flex; align-items: flex-start; gap: 15px;">
                                <a href="https://www.siemens.com/" target="_blank">
                                    <img src="/img/logos/siemens.jpeg" alt="Siemens Logo" style="width: 80px; height: 70px; object-fit: contain; flex-shrink: 0; cursor: pointer;">
                                </a>
                                <div>
                                    <h3 style="margin: 0 0 8px 0; color: #333; font-size: 20px;">
                                        Siemens (St. Petersburg)
                                    </h3>
                                    <p style="margin: 0 0 10px 0; color: #333; font-size: 16px; font-weight: 500;">Algorithm Intern & Algorithm Engineer</p>
                                    <p style="margin: 0; color: #666; font-size: 14px; line-height: 1.6;">Deep learning-based speech synthesis systems and image recognition algorithms.</p>
                                </div>
                            </div>
                            <span style="color: #666; font-size: 14px; white-space: nowrap;">2018.05 - 2019.09</span>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>

<!-- Publications Section -->
<div id="publications" class="container" style="margin-top: 0px; padding-top: 10px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <h2 style="color: #333; margin-bottom: 30px;"><i class="fa fa-book"></i> Publications</h2>
            
            <div style="margin-bottom: 25px;">
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div class="publication-flex" style="display: flex; align-items: flex-start; gap: 20px;">
                            <div class="publication-image">
                                <img src="/img/paper_placeholder_1.png" alt="Paper 1" style="width: 160px; height: auto; object-fit: contain; border-radius: 5px; flex-shrink: 0;">
                            </div>
                            <div class="publication-content" style="flex: 1;">
                                <h3 style="margin: 0 0 10px 0; color: #333; font-size: 18px; font-weight: normal;">Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability</h3>
                                <p style="color: #666; margin: 5px 0; font-size: 14px;">
                                    <strong>Xiaoxu Zhu</strong>, Junhua Li
                                </p>
                                <p style="color: #333; margin: 5px 0 15px 0; font-size: 14px; font-style: italic;">
                                    arxiv, 2025
                                </p>
                                <div style="margin-bottom: 15px;">
                                    <a href="https://arxiv.org/pdf/2507.17851" target="_blank" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">pdf</a>
                                    <a href="javascript:void(0)" onclick="toggleAbstract('abstract1')" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">abstract</a>
                                    <a href="javascript:void(0)" onclick="toggleBibtex('bibtex1')" style="border: 1px solid #ddd; color: #333; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">bibtex</a>
                                </div>
                                <div id="abstract1" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <p style="color: #333; font-size: 14px; line-height: 1.6;">
                                        Speech pretrained models contain task-specific information across different layers, but decoupling content and timbre information remains challenging as removing speaker-specific information often causes content loss. Current research lacks direct metrics to quantify timbre residual in model encodings, relying on indirect evaluation through downstream tasks. This paper addresses these challenges through interpretability-based speaker disentanglement in speech pretraining models. We quantitatively evaluate timbre residual in model embeddings and improve speaker disentanglement using interpretive representations. Our contributions include: (1) InterpTRQE-SptME Benchmark - a timbre residual recognition framework using interpretability. The benchmark concatenates content embeddings with timbre embeddings for speaker classification, then applies Gradient SHAP Explainer to quantify timbre residual. We evaluate seven speech pretraining model variations. (2) InterpTF-SptME method - an interpretability-based timbre filtering approach using SHAP Noise and SHAP Cropping techniques. This model-agnostic method transforms intermediate encodings to remove timbre while preserving content. Experiments on VCTK dataset with HuBERT LARGE demonstrate successful content preservation and significant speaker disentanglement optimization. Results show the SHAP Noise method can reduce timbre residual from 18.05% to near 0% while maintaining content integrity, contributing to enhanced performance in content-related speech processing tasks and preventing timbre privacy leakage.
                                    </p>
                                </div>
                                <div id="bibtex1" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <pre style="color: #333; font-size: 12px; margin: 0; white-space: pre-wrap;">@article{zhu2024speaker,
  title={Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability},
  author={Zhu, Xiaoxu and Li, Junhua},
  journal={arXiv preprint arXiv:2507.17851},
  year={2024}
}</pre>
                                </div>
                            </div>
                        </div>
                    </li>

                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div class="publication-flex" style="display: flex; align-items: flex-start; gap: 20px;">
                            <div class="publication-image">
                                <img src="/img/paper_placeholder_2.png" alt="Paper 2" style="width: 160px; height: auto; object-fit: contain; border-radius: 5px; flex-shrink: 0;">
                            </div>
                            <div class="publication-content" style="flex: 1;">
                                <h3 style="margin: 0 0 10px 0; color: #333; font-size: 18px; font-weight: normal;">A polyphone BERT for Polyphone Disambiguation in Mandarin Chinese</h3>
                                <p style="color: #666; margin: 5px 0; font-size: 14px;">
                                    Song Zhang, Ken Zheng, <strong>Xiaoxu Zhu</strong>, Baoxiang Li
                                </p>
                                <p style="color: #333; margin: 5px 0 15px 0; font-size: 14px; font-style: italic;">
                                    Interspeech, 2022
                                </p>
                                <div style="margin-bottom: 15px;">
                                    <a href="https://www.isca-archive.org/interspeech_2022/zhang22b_interspeech.pdf" target="_blank" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">pdf</a>
                                    <a href="javascript:void(0)" onclick="toggleAbstract('abstract2')" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">abstract</a>
                                    <a href="javascript:void(0)" onclick="toggleBibtex('bibtex2')" style="border: 1px solid #ddd; color: #333; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">bibtex</a>
                                </div>
                                <div id="abstract2" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <p style="color: #333; font-size: 14px; line-height: 1.6;">
                                        Grapheme-to-phoneme (G2P) conversion is an indispensable part of the Chinese Mandarin text-to-speech (TTS) system, and the core of G2P conversion is to solve the problem of polyphone disambiguation, which is to pick up the correct pronunciation for several candidates for a Chinese polyphonic character. In this paper, we propose a Chinese polyphone BERT model to predict the pronunciations of Chinese polyphonic characters. Firstly, we create 741 new Chinese monophonic characters from 354 source Chinese polyphonic characters by pronunciation. Then we get a Chinese polyphone BERT by extending a pre-trained Chinese BERT with 741 new Chinese monophonic characters and adding a corresponding embedding layer for new tokens, which is initialized by the embeddings of source Chinese polyphonic characters. In this way, we can turn the polyphone disambiguation task into a pre-training task of the Chinese polyphone BERT. Experimental results demonstrate the effectiveness of the proposed model, and the polyphone BERT model obtain 2% (from 92.1% to 94.1%) improvement of average accuracy compared with the BERT-based classifier model, which is the prior state-of-the-art in polyphone disambiguation.
                                    </p>
                                </div>
                                <div id="bibtex2" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <pre style="color: #333; font-size: 12px; margin: 0; white-space: pre-wrap;">@inproceedings{zhang2022polyphone,
  title={A polyphone BERT for Polyphone Disambiguation in Mandarin Chinese},
  author={Zhang, Song and Zheng, Ken and Zhu, Xiaoxu and Li, Baoxiang},
  booktitle={Proc. Interspeech 2022},
  year={2022},
  note={Accepted for INTERSPEECH 2022}
}</pre>
                                </div>
                            </div>
                        </div>
                    </li>

                    <li style="margin-bottom: 25px; padding: 25px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <div class="publication-flex" style="display: flex; align-items: flex-start; gap: 20px;">
                            <div class="publication-image">
                                <img src="/img/paper_placeholder_3.png" alt="Paper 3" style="width: 160px; height: auto; object-fit: contain; border-radius: 5px; flex-shrink: 0;">
                            </div>
                            <div class="publication-content" style="flex: 1;">
                                <h3 style="margin: 0 0 10px 0; color: #333; font-size: 18px; font-weight: normal;">Multimodal Sentiment Analysis via Efficient Multimodal Transformer and Modality-Aware Adaptive Training Strategy</h3>
                                <p style="color: #666; margin: 5px 0; font-size: 14px;">
                                    C. Ding, D. Zong, B. Li, S. Zhang, <strong>X. Zhu</strong>, G. Zhong, D. Zhou
                                </p>
                                <p style="color: #333; margin: 5px 0 15px 0; font-size: 14px; font-style: italic;">
                                    IEEE/ACM MuSe-Mimic, 2023
                                </p>
                                <div style="margin-bottom: 15px;">
                                    <a href="https://dl.acm.org/doi/10.1145/3606039.3613113" target="_blank" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">pdf</a>
                                    <a href="javascript:void(0)" onclick="toggleAbstract('abstract3')" style="border: 1px solid #ddd; color: #333; margin-right: 8px; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">abstract</a>
                                    <a href="javascript:void(0)" onclick="toggleBibtex('bibtex3')" style="border: 1px solid #ddd; color: #333; text-decoration: none; padding: 4px 8px; border-radius: 3px; font-size: 11px; display: inline-block; background: #fff; cursor: pointer;">bibtex</a>
                                </div>
                                <div id="abstract3" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <p style="color: #333; font-size: 14px; line-height: 1.6;">
                                        In this paper, we present the solution to the MuSe-Mimic subchallenge of the 4th Multimodal Sentiment Analysis Challenge. This sub-challenge aims to predict the level of approval, disappointment and uncertainty in user-generated video clips. In our experiments, we found that naive joint training of multiple modalities by late fusion would result in insufficient learning of unimodal features. Moreover, different modalities contribute differently to MuSe-Mimic. Relying solely on multimodal features or treating unimodal features equally may limit the model's generalization performance. To address these challenges, we propose an efficient multimodal transformer equipped with a modality-aware adaptive training strategy to facilitate optimal joint training on multimodal sequence inputs. This framework holds promise in leveraging cross-modal interactions while ensuring adequate learning of unimodal features. Our model achieves the mean Pearson's Correlation Coefficient of .729 (ranking 2nd), outperforming official baseline result of .473. Our code is available at https://github.com/dingchaoyue/Multimodal-Emotion-Recognition-MER-and-MuSe-2023-Challenges.
                                    </p>
                                </div>
                                <div id="bibtex3" style="display: none; margin-top: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                    <pre style="color: #333; font-size: 12px; margin: 0; white-space: pre-wrap;">@inproceedings{ding2023multimodal,
  title={Multimodal Sentiment Analysis via Efficient Multimodal Transformer and Modality-Aware Adaptive Training Strategy},
  author={Ding, C. and Zong, D. and Li, B. and Zhang, S. and Zhu, X. and Zhong, G. and Zhou, D.},
  booktitle={Proceedings of the 4th International on Multimodal Sentiment Analysis Workshop and Challenge},
  pages={263--270},
  year={2023},
  organization={ACM}
}</pre>
                                </div>
                            </div>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>

<!-- Contributions Section -->
<div id="contributions" class="container" style="margin-top: 0px; padding-top: 10px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <h2 style="color: #333; margin-bottom: 20px;"><i class="fa fa-trophy"></i> Contributions</h2>
            
            <!-- Research Projects -->
            <div style="margin-bottom: 25px;">
                <h3 style="color: #333; margin-bottom: 20px;"> Research Projects</h3>
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>基于生成式大模型的公路路基突发性灾害预警技术与方法【国家重点课题】</strong><br>
                        <span style="color: #666; font-size: 14px;"><b>专题负责人</b> | 国家自然科学基金委员会高技术研究发展中心 | SQ2024YFB2600035</span>
                    </li>
                    <li style="margin-bottom: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>基于语义知识图谱的建筑工程标准国际化共性关键技术【国家重点课题】</strong><br>
                        <span style="color: #666; font-size: 14px;"><b>项目骨干</b> | 中国21世纪议程管理中心 | SQ2024YFC3800085</span>
                    </li>
                </ul>
            </div>

            <!-- Patents -->
            <div style="margin-bottom: 25px;">
                <h3 style="color: #333; margin-bottom: 20px;"> Patents</h3>
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 10px; padding: 10px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>多音字读音预测网络的训练方法、语音生成方法及装置</strong> [CN115273809B]
                    </li>
                    <li style="margin-bottom: 10px; padding: 10px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>残差网络的训练和语音合成方法、装置、设备及介质</strong> [CN112562655A]
                    </li>
                    <li style="margin-bottom: 10px; padding: 10px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>模型训练和语音合成方法、装置、设备及介质</strong> [CN116206591A]
                    </li>
                    <li style="margin-bottom: 10px; padding: 10px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>一种模型训练和语音合成方法、装置、设备及介质</strong> [CN115294955B]
                    </li>
                </ul>
            </div>

            <!-- Competitions -->
            <div style="margin-bottom: 25px;">
                <h3 style="color: #333; margin-bottom: 20px;"> Competitions & Awards</h3>
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>2024 Intel Mini Hackathon</strong> - Excellent Work Award<br>
    </li>
                    <li style="margin-bottom: 15px; padding: 15px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <strong>2023 ACM MuSe-Mimic Subchallenge</strong> - Second Place<br>
    </li>
</ul>
            </div>

            <!-- Open Source Contributions -->
            <div style="margin-bottom: 15px;">
                <h3 style="color: #333; margin-bottom: 20px;"> Open Source Contributions</h3>
                <div style="padding: 20px; background: white; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <h4 style="margin-top: 0; color: #333;">
                        <a href="https://github.com/xiph/LPCNet/commit/c1e85f88d908533c5600dbdd800ac589e15747f4" target="_blank" style="color: #333; text-decoration: none;">
                            <i class="fa fa-github"></i> LPCNet - Pre-compute GRU B Conditioning
                        </a>
                    </h4>
                    <p style="color: #666; margin: 10px 0; font-size: 14px; line-height: 1.6;">
                        <strong>Performance Optimization:</strong> Implemented pre-computation of GRU B conditioning vectors to achieve approximately <strong>10% speed improvement</strong> in LPCNet inference. This optimization reduces computational overhead by caching frequently used conditioning vectors, significantly improving real-time speech synthesis performance.
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Contact Section -->
<div id="contact" class="container" style="margin-top: 0px; padding-top: 10px;">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1 col-md-12 col-md-offset-0">
            <h2 style="color: #333; margin-bottom: 30px;"><i class="fa fa-envelope"></i> Contact</h2>
            
            <div style="padding: 10px; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                <p style="font-size: 16px; line-height: 1.6; margin-bottom: 15px;">
                    I am always eager to connect and exchange ideas with fellow researchers in <strong>large speech models</strong> and <strong>speech AI</strong>. 
                    Feel free to reach out if you'd like to discuss research collaborations or share insights!
                </p>
                <div style="display: flex; align-items: center; gap: 10px; flex-wrap: wrap;">
                    <div style="display: flex; align-items: center; gap: 8px;">
                        <i class="fa fa-envelope" style="color: #0085a1; font-size: 18px;"></i>
                        <a href="mailto:zhuxiaoxuhit@gmail.com" style="color: #0085a1; text-decoration: none; font-weight: 500;">
                            zhuxiaoxuhit@gmail.com
                        </a>
                    </div>
                    <div style="display: flex; align-items: center; gap: 8px;">
                        <i class="fa fa-wechat" style="color: #0085a1; font-size: 18px;"></i>
                        <button onclick="toggleWechatQR()" style="background: #0085a1; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 14px;">
                            Show WeChat QR Code
                        </button>
                    </div>
                </div>
                <div id="wechat-qr" style="display: none; margin-top: 20px; text-align: center;">
                    <img src="/img/wechat.png" alt="WeChat QR Code" style="max-width: 200px; border: 1px solid #ddd; border-radius: 8px;">
                    <p style="color: #666; font-size: 14px; margin-top: 10px;">Scan to add me on WeChat</p>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- JavaScript for Publications -->
<script>
function toggleAbstract(id) {
    var element = document.getElementById(id);
    if (element.style.display === "none" || element.style.display === "") {
        element.style.display = "block";
        // Hide any open bibtex
        var bibtexId = id.replace('abstract', 'bibtex');
        var bibtexElement = document.getElementById(bibtexId);
        if (bibtexElement) {
            bibtexElement.style.display = "none";
        }
    } else {
        element.style.display = "none";
    }
}

function toggleBibtex(id) {
    var element = document.getElementById(id);
    if (element.style.display === "none" || element.style.display === "") {
        element.style.display = "block";
        // Hide any open abstract
        var abstractId = id.replace('bibtex', 'abstract');
        var abstractElement = document.getElementById(abstractId);
        if (abstractElement) {
            abstractElement.style.display = "none";
        }
    } else {
        element.style.display = "none";
    }
}

function toggleWechatQR() {
    var qrElement = document.getElementById('wechat-qr');
    var button = event.target;
    
    if (qrElement.style.display === "none" || qrElement.style.display === "") {
        qrElement.style.display = "block";
        button.textContent = "Hide WeChat QR Code";
        button.style.background = "#d9534f";
    } else {
        qrElement.style.display = "none";
        button.textContent = "Show WeChat QR Code";
        button.style.background = "#0085a1";
    }
}
</script>
